# ASDSpeechEmotionRecognition

The speech emotion recognition solution was created using machine learning and deep learning techniques. Ensemble learning was used, which involves joining multiple machine learning algorithms using voting to classify speech recordings in real-time. A support vector machine (SVM), a multilayer perceptron (MLP), and a recurrent neural network model was trained on the Ryerson Audio-Visual Database of Emotional Speech and Songs (RAVDESS), the Toronto Emotional Speech Set (TESS), the Crowd-sourced Emotional Multimodal Actors Dataset (CREMA-D), and a custom dataset which contains utterances from the three datasets with added background noise. Two separate audio feature sets were used, and their performances were compared. One of them was a custom feature set and the other one contained features from a popular speech emotion feature set.

Rezwan


