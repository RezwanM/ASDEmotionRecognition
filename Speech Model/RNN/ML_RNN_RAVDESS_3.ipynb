{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************************************************************\n",
    "# Rezwan Matin\n",
    "# Thesis B\n",
    "# Filename: ML_RNN_RAVDESS_3.py\n",
    "# Date: 5/17/20\n",
    "#\n",
    "# Objective:\n",
    "# 26 MFCCs (mean) and 26 MFCCs (standard deviation), ZCR; Transpose X_Train Tensor so that row=features and column=frames.\n",
    "#\n",
    "#*************************************************************************************\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as rosa\n",
    "import glob\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save directory path in 'path'\n",
    "path = r'C:/Books/Texas State Books/Fall 2019/Thesis A/Corpus/Simulated/RAVDESS/All'\n",
    "\n",
    "# Create a list of audio file names 'file_list'\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "# Declare an empty list to store the length (no. of frames) for each sample (audio).\n",
    "num_frames = []\n",
    "\n",
    "i=0\n",
    "\n",
    "sum = 0\n",
    "\n",
    "# Loop for calculating averge number of frames for the dataset.\n",
    "for filename in file_list:\n",
    "    \n",
    "    # Read WAV file. 'rosa.core.load' returns sampling frequency in 'fs' and audio signal in 'sig'\n",
    "    sig, fs = rosa.core.load(path + '/' + file_list[i], sr=None)\n",
    "    \n",
    "    # 'rosa.feature.mfcc' extracts n_mfccs from signal and stores it into 'mfcc_feat'\n",
    "    mfcc_feat = rosa.feature.mfcc(y=sig, sr=fs, n_mfcc=26)\n",
    "    \n",
    "    num_frames.insert(i, mfcc_feat.shape[1])\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "# Print the list containing the frame lengths of all the samples\n",
    "num_frames\n",
    "\n",
    "# Calculate the Median of the number of frames for all samples. This will then be used to cap the maximum number of frames per sample, which in turn will be used as the number of RNN units.\n",
    "median_num_frames = statistics.median(num_frames)\n",
    "\n",
    "# Calculate the Mean of the number of frames for all samples. This is just to cross-check with the Median value.\n",
    "average_num_frames = statistics.mean(num_frames)\n",
    "\n",
    "# Print the average number of frames for the dataset.\n",
    "#average_num_frames\n",
    "\n",
    "# Print the median number of frames for the dataset.\n",
    "median_num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.39860973e-315, 1.40590150e-315, 1.71249639e-003, ...,\n",
       "       9.21448291e-002, 9.21448291e-002, 8.00000000e+000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert float to integer.\n",
    "median_num_frames = int(median_num_frames)\n",
    "\n",
    "# Save directory path in 'path'\n",
    "path = r'C:/Books/Texas State Books/Fall 2019/Thesis A/Corpus/Simulated/RAVDESS/All'\n",
    "\n",
    "# Create a list of audio file names 'file_list'\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "# Declare a dummy Numpy array (row vector)\n",
    "result_array = np.empty([1, (27*median_num_frames)+1])\n",
    "\n",
    "i=0\n",
    "\n",
    "# Loop for feature extraction.\n",
    "for filename in file_list:\n",
    "    \n",
    "    # Read WAV file. 'rosa.core.load' returns sampling frequency in 'fs' and audio signal in 'sig'\n",
    "    sig, fs = rosa.core.load(path + '/' + file_list[i], sr=None)\n",
    "    \n",
    "    # 'rosa.feature.mfcc' extracts n_mfccs from signal and stores it into 'mfcc_feat'\n",
    "    mfcc_feat = rosa.feature.mfcc(y=sig, sr=fs, n_mfcc=26)\n",
    "    \n",
    "    # Calculate the average zero crossing rate (utterance-level feature) using 'rosa.feat.zero_crossing_rate()' and 'np.mean' method. '.T' transposes the rows and columns. 'axis=0' indicates average is calculated column-wise\n",
    "    zcross_feat = rosa.feature.zero_crossing_rate(sig)\n",
    "    \n",
    "    # Append the two 2D arrays into a single 2D array called 'mfcczcr_feat'.\n",
    "    mfcczcr_feat = np.append(mfcc_feat, zcross_feat, axis=0)\n",
    "    \n",
    "    # Transpose the array to flip the rows and columns. This is done so that the features become column parameters, making each row an audio frame.\n",
    "    transp_mfcczcr_feat = mfcczcr_feat.T\n",
    "    \n",
    "    # Note: The 'cap frame number' is basically the limit we set for the number of frames for each sample, so that all samples have equal dimensions.\n",
    "    if transp_mfcczcr_feat.shape[0]<median_num_frames:\n",
    "\n",
    "        # If number of frames is smaller than the cap frame number, we pad the array in order to reach our desired dimensions.\n",
    "\n",
    "        # Pad the array so that it matches the cap frame number. The second value in the argument contains two tuples which indicate which way to pad how much.  \n",
    "        transp_mfcczcr_feat = np.pad(transp_mfcczcr_feat, ((0, median_num_frames-transp_mfcczcr_feat.shape[0]), (0,0)), 'mean')\n",
    "\n",
    "    elif transp_mfcczcr_feat.shape[0]>median_num_frames:\n",
    "\n",
    "        # If number of frames is larger than the cap frame number, we delete rows (frames) which exceed the cap frame number in order to reach our desired dimensions.\n",
    "\n",
    "        # Define a tuple which contains the range of the row indices to delete.\n",
    "        row_del_index = (range(median_num_frames, transp_mfcczcr_feat.shape[0], 1))\n",
    "\n",
    "        transp_mfcczcr_feat = np.delete(transp_mfcczcr_feat, row_del_index, axis=0)\n",
    "\n",
    "    else:\n",
    "        # If number of frames match the cap frame length, perfect!\n",
    "        transp_mfcczcr_feat = transp_mfcczcr_feat\n",
    "    \n",
    "    # Transpose again to flip the rows and columns. This is done so that the features become row parameters, making each column an audio frame.\n",
    "    transp2_mfcczcr_feat = transp_mfcczcr_feat.T\n",
    "    \n",
    "    # Flatten the entire 2D Numpy array into 1D Numpy array. So, the first 27 values of the 1D array represent the 26 MFCC and ZCR features for first frame, the second 27 represent the features for second frame, and so on till the final (cap) frame.\n",
    "    # 'C' means row-major ordered flattening.\n",
    "    mfcczcr_feat_flatten = transp2_mfcczcr_feat.flatten('C')\n",
    "    \n",
    "    # Save emotion label from file name. 'path' contains directory's address, 'file_list' contains file name, and '/' joins the two to form file's address\n",
    "    label = os.path.splitext(os.path.basename(path + '/' + file_list[i]))[0].split('-')[2]\n",
    "    \n",
    "    # Create a new Numpy array 'sample' to store features along with label\n",
    "    sample = np.insert(mfcczcr_feat_flatten, obj=27*median_num_frames, values=label)\n",
    "    \n",
    "    result_array = np.append(result_array, sample)\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "# Print out the 1D Numpy array\n",
    "result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13424356,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 9316)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 1D Numpy array to 2D array. Argument must be a Tuple. i+1 because we have i samples (audio files) plus a dummy row.\n",
    "result_array = np.reshape(result_array, (i+1,-1))\n",
    "\n",
    "# Delete first dummy row from 2D array\n",
    "result_array = np.delete(result_array, 0, 0)\n",
    "\n",
    "# Print final 2D Numpy array \n",
    "result_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9306</th>\n",
       "      <th>9307</th>\n",
       "      <th>9308</th>\n",
       "      <th>9309</th>\n",
       "      <th>9310</th>\n",
       "      <th>9311</th>\n",
       "      <th>9312</th>\n",
       "      <th>9313</th>\n",
       "      <th>9314</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1236</td>\n",
       "      <td>-739.243692</td>\n",
       "      <td>-739.243692</td>\n",
       "      <td>-738.248973</td>\n",
       "      <td>-737.841828</td>\n",
       "      <td>-739.243692</td>\n",
       "      <td>-738.636153</td>\n",
       "      <td>-738.127835</td>\n",
       "      <td>-739.182470</td>\n",
       "      <td>-739.243692</td>\n",
       "      <td>-739.243692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1237</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>-774.800100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.083984</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.111328</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1238</td>\n",
       "      <td>-763.928486</td>\n",
       "      <td>-761.478778</td>\n",
       "      <td>-761.991078</td>\n",
       "      <td>-765.182222</td>\n",
       "      <td>-764.015812</td>\n",
       "      <td>-761.986743</td>\n",
       "      <td>-760.425199</td>\n",
       "      <td>-761.124071</td>\n",
       "      <td>-762.299321</td>\n",
       "      <td>-761.762594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>0.060662</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1239</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>-706.572796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>0.071194</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>-662.226612</td>\n",
       "      <td>-662.443686</td>\n",
       "      <td>-662.698916</td>\n",
       "      <td>-664.030596</td>\n",
       "      <td>-663.867629</td>\n",
       "      <td>-661.720699</td>\n",
       "      <td>-661.266040</td>\n",
       "      <td>-662.856644</td>\n",
       "      <td>-664.752357</td>\n",
       "      <td>-663.897425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1241</td>\n",
       "      <td>-798.248507</td>\n",
       "      <td>-798.248507</td>\n",
       "      <td>-782.634697</td>\n",
       "      <td>-767.108723</td>\n",
       "      <td>-772.899409</td>\n",
       "      <td>-752.477857</td>\n",
       "      <td>-752.859553</td>\n",
       "      <td>-775.936689</td>\n",
       "      <td>-794.248732</td>\n",
       "      <td>-797.577087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.062682</td>\n",
       "      <td>0.062682</td>\n",
       "      <td>0.062682</td>\n",
       "      <td>0.062682</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1242</td>\n",
       "      <td>-842.616981</td>\n",
       "      <td>-840.760598</td>\n",
       "      <td>-839.359242</td>\n",
       "      <td>-839.649656</td>\n",
       "      <td>-839.741711</td>\n",
       "      <td>-839.484332</td>\n",
       "      <td>-839.550682</td>\n",
       "      <td>-839.198635</td>\n",
       "      <td>-839.762744</td>\n",
       "      <td>-840.935902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1243</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>-779.099742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1244</td>\n",
       "      <td>-690.138542</td>\n",
       "      <td>-690.138542</td>\n",
       "      <td>-690.138542</td>\n",
       "      <td>-690.138542</td>\n",
       "      <td>-690.138542</td>\n",
       "      <td>-690.138542</td>\n",
       "      <td>-690.138542</td>\n",
       "      <td>-690.042850</td>\n",
       "      <td>-690.065892</td>\n",
       "      <td>-690.138542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1245</td>\n",
       "      <td>-726.561085</td>\n",
       "      <td>-726.561085</td>\n",
       "      <td>-726.561085</td>\n",
       "      <td>-726.561085</td>\n",
       "      <td>-726.561085</td>\n",
       "      <td>-726.561085</td>\n",
       "      <td>-726.561085</td>\n",
       "      <td>-726.561085</td>\n",
       "      <td>-726.561085</td>\n",
       "      <td>-726.226427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.123047</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.077148</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.083883</td>\n",
       "      <td>0.083883</td>\n",
       "      <td>0.083883</td>\n",
       "      <td>0.083883</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1246</td>\n",
       "      <td>-685.361690</td>\n",
       "      <td>-685.361690</td>\n",
       "      <td>-685.361690</td>\n",
       "      <td>-685.361690</td>\n",
       "      <td>-685.361690</td>\n",
       "      <td>-685.361690</td>\n",
       "      <td>-685.361690</td>\n",
       "      <td>-685.361690</td>\n",
       "      <td>-685.067420</td>\n",
       "      <td>-684.929422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1247</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>-695.747715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.224121</td>\n",
       "      <td>0.170898</td>\n",
       "      <td>0.168945</td>\n",
       "      <td>0.092145</td>\n",
       "      <td>0.092145</td>\n",
       "      <td>0.092145</td>\n",
       "      <td>0.092145</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 9316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5  \\\n",
       "1236 -739.243692 -739.243692 -738.248973 -737.841828 -739.243692 -738.636153   \n",
       "1237 -774.800100 -774.800100 -774.800100 -774.800100 -774.800100 -774.800100   \n",
       "1238 -763.928486 -761.478778 -761.991078 -765.182222 -764.015812 -761.986743   \n",
       "1239 -706.572796 -706.572796 -706.572796 -706.572796 -706.572796 -706.572796   \n",
       "1240 -662.226612 -662.443686 -662.698916 -664.030596 -663.867629 -661.720699   \n",
       "1241 -798.248507 -798.248507 -782.634697 -767.108723 -772.899409 -752.477857   \n",
       "1242 -842.616981 -840.760598 -839.359242 -839.649656 -839.741711 -839.484332   \n",
       "1243 -779.099742 -779.099742 -779.099742 -779.099742 -779.099742 -779.099742   \n",
       "1244 -690.138542 -690.138542 -690.138542 -690.138542 -690.138542 -690.138542   \n",
       "1245 -726.561085 -726.561085 -726.561085 -726.561085 -726.561085 -726.561085   \n",
       "1246 -685.361690 -685.361690 -685.361690 -685.361690 -685.361690 -685.361690   \n",
       "1247 -695.747715 -695.747715 -695.747715 -695.747715 -695.747715 -695.747715   \n",
       "\n",
       "               6           7           8           9  ...      9306      9307  \\\n",
       "1236 -738.127835 -739.182470 -739.243692 -739.243692  ...  0.066450  0.066450   \n",
       "1237 -774.800100 -774.800100 -774.800100 -774.800100  ...  0.044922  0.058594   \n",
       "1238 -760.425199 -761.124071 -762.299321 -761.762594  ...  0.060662  0.060662   \n",
       "1239 -706.572796 -706.572796 -706.572796 -706.572796  ...  0.071194  0.071194   \n",
       "1240 -661.266040 -662.856644 -664.752357 -663.897425  ...  0.068974  0.068974   \n",
       "1241 -752.859553 -775.936689 -794.248732 -797.577087  ...  0.003906  0.004883   \n",
       "1242 -839.550682 -839.198635 -839.762744 -840.935902  ...  0.053795  0.053795   \n",
       "1243 -779.099742 -779.099742 -779.099742 -779.099742  ...  0.073165  0.073165   \n",
       "1244 -690.138542 -690.042850 -690.065892 -690.138542  ...  0.069006  0.069006   \n",
       "1245 -726.561085 -726.561085 -726.561085 -726.226427  ...  0.073242  0.123047   \n",
       "1246 -685.361690 -685.361690 -685.067420 -684.929422  ...  0.075679  0.075679   \n",
       "1247 -695.747715 -695.747715 -695.747715 -695.747715  ...  0.085938  0.156250   \n",
       "\n",
       "          9308      9309      9310      9311      9312      9313      9314  \\\n",
       "1236  0.066450  0.066450  0.066450  0.066450  0.066450  0.066450  0.066450   \n",
       "1237  0.083984  0.096680  0.111328  0.093750  0.083008  0.107422  0.113281   \n",
       "1238  0.060662  0.060662  0.060662  0.060662  0.060662  0.060662  0.060662   \n",
       "1239  0.071194  0.071194  0.071194  0.071194  0.071194  0.071194  0.071194   \n",
       "1240  0.068974  0.068974  0.068974  0.068974  0.068974  0.068974  0.068974   \n",
       "1241  0.004883  0.000977  0.000977  0.062682  0.062682  0.062682  0.062682   \n",
       "1242  0.053795  0.053795  0.053795  0.053795  0.053795  0.053795  0.053795   \n",
       "1243  0.073165  0.073165  0.073165  0.073165  0.073165  0.073165  0.073165   \n",
       "1244  0.069006  0.069006  0.069006  0.069006  0.069006  0.069006  0.069006   \n",
       "1245  0.073242  0.077148  0.055664  0.083883  0.083883  0.083883  0.083883   \n",
       "1246  0.075679  0.075679  0.075679  0.075679  0.075679  0.075679  0.075679   \n",
       "1247  0.224121  0.170898  0.168945  0.092145  0.092145  0.092145  0.092145   \n",
       "\n",
       "      Emotion  \n",
       "1236      8.0  \n",
       "1237      8.0  \n",
       "1238      8.0  \n",
       "1239      8.0  \n",
       "1240      8.0  \n",
       "1241      8.0  \n",
       "1242      8.0  \n",
       "1243      8.0  \n",
       "1244      8.0  \n",
       "1245      8.0  \n",
       "1246      8.0  \n",
       "1247      8.0  \n",
       "\n",
       "[12 rows x 9316 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=result_array)\n",
    "# Label only the last (target) column\n",
    "df = df.rename({27*median_num_frames: \"Emotion\"}, axis='columns')\n",
    "# Delete unnecessary emotion data (calm)\n",
    "df.drop(df[df['Emotion'] == 2.0].index, inplace = True)\n",
    "# Reset row (sample) indexing\n",
    "df = df.reset_index(drop=True)\n",
    "df.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0    192\n",
       "7.0    192\n",
       "6.0    192\n",
       "5.0    192\n",
       "4.0    192\n",
       "3.0    192\n",
       "1.0     96\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0    192\n",
       "7.0    192\n",
       "6.0    192\n",
       "5.0    192\n",
       "4.0    192\n",
       "3.0    192\n",
       "1.0    192\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance the dataset for equal number of samples for each class.\n",
    "# Separate majority and minority classes\n",
    "df_minority = df[df.Emotion==1.0]\n",
    "df_majority3 = df[df.Emotion==3.0]\n",
    "df_majority4 = df[df.Emotion==4.0]\n",
    "df_majority5 = df[df.Emotion==5.0]\n",
    "df_majority6 = df[df.Emotion==6.0]\n",
    "df_majority7 = df[df.Emotion==7.0]\n",
    "df_majority8 = df[df.Emotion==8.0]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=192,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_minority_upsampled, df_majority3, df_majority4, df_majority5, df_majority6, df_majority7, df_majority8])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.Emotion.value_counts()\n",
    "\n",
    "# Reset row (sample) indexing\n",
    "df_upsampled = df_upsampled.reset_index(drop=True)\n",
    "\n",
    "df_upsampled['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 8. 8. 8.]\n"
     ]
    }
   ],
   "source": [
    "# Extract target feature 'Emotion' in a vector y. Indexing from 0\n",
    "y = df_upsampled.iloc[0:1344, 27*median_num_frames].values\n",
    "# Extract features 'buying' and 'safety' in a vector X. Indexing from 0\n",
    "X = df_upsampled.iloc[0:1344, list(range(27*median_num_frames))].values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 9315) (1008,)\n",
      "(336, 9315) (336,)\n"
     ]
    }
   ],
   "source": [
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "# Standardize the inputs\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val\n",
    "\n",
    "del X_train, X_test\n",
    "\n",
    "print(X_train_centered.shape, y_train.shape)\n",
    "print(X_test_centered.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 345, 27) (1008,)\n",
      "(336, 345, 27) (336,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "# One-Hot Encode the classes\n",
    "y_train_onehot = keras.utils.to_categorical(y_train)\n",
    "\n",
    "# Reshaping X_train and X_test to 3D Numpy arrays for feeding into the RNN. RNNs require 3D array input.\n",
    "# 3D dimensions are (layers, rows, columns).\n",
    "X_train_3D = np.reshape(X_train_centered, (X_train_centered.shape[0], median_num_frames, 27))\n",
    "X_test_3D = np.reshape(X_test_centered, (X_test_centered.shape[0], median_num_frames, 27))\n",
    "\n",
    "print(X_train_3D.shape, y_train.shape)\n",
    "print(X_test_3D.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 27, 345) (1008,)\n",
      "(336, 27, 345) (336,)\n"
     ]
    }
   ],
   "source": [
    "# Transpose tensors so that rows=features and columns=frames.\n",
    "X_train_3D_posed = tf.transpose(X_train_3D, perm=[0, 2, 1])\n",
    "X_test_3D_posed = tf.transpose(X_test_3D, perm=[0, 2, 1])\n",
    "\n",
    "print(X_train_3D_posed.shape, y_train.shape)\n",
    "print(X_test_3D_posed.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object/instance 'model' for the 'Sequential()' class.\n",
    "model = keras.models.Sequential()\n",
    "    \n",
    "model.add(\n",
    "    keras.layers.SimpleRNN( units=27,\n",
    "                input_shape=(27, median_num_frames),\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                activation='tanh'))\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Dense( units=y_train_onehot.shape[1],\n",
    "                input_dim=27,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning rate schedule. This can then be passed as the learning rate for the optimizer.\n",
    "lrate = keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate=0.01, decay_steps=1000, decay_rate=0.8)\n",
    "\n",
    "adam_optimizer = keras.optimizers.Adam(\n",
    "                    learning_rate=lrate, beta_1=0.9, beta_2=0.999, epsilon=1e-06) #1e-06 gave better result than default value 1e-07\n",
    "\n",
    "model.compile(optimizer=adam_optimizer,\n",
    "                    loss='kullback_leibler_divergence')\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 907 samples, validate on 101 samples\n",
      "Epoch 1/50\n",
      "907/907 [==============================] - 2s 2ms/sample - loss: 1.7456 - val_loss: 1.3714\n",
      "Epoch 2/50\n",
      "907/907 [==============================] - 1s 657us/sample - loss: 1.2256 - val_loss: 1.2385\n",
      "Epoch 3/50\n",
      "907/907 [==============================] - 1s 666us/sample - loss: 0.9422 - val_loss: 1.1811\n",
      "Epoch 4/50\n",
      "907/907 [==============================] - 1s 665us/sample - loss: 0.7309 - val_loss: 1.2038\n",
      "Epoch 5/50\n",
      "907/907 [==============================] - 1s 675us/sample - loss: 0.5962 - val_loss: 1.1768\n",
      "Epoch 6/50\n",
      "907/907 [==============================] - 1s 712us/sample - loss: 0.4475 - val_loss: 1.2913\n",
      "Epoch 7/50\n",
      "907/907 [==============================] - 1s 653us/sample - loss: 0.3932 - val_loss: 1.1729\n",
      "Epoch 8/50\n",
      "907/907 [==============================] - 1s 660us/sample - loss: 0.2068 - val_loss: 1.1934\n",
      "Epoch 9/50\n",
      "907/907 [==============================] - 1s 662us/sample - loss: 0.1442 - val_loss: 1.2333\n",
      "Epoch 10/50\n",
      "907/907 [==============================] - 1s 656us/sample - loss: 0.1217 - val_loss: 1.3043\n",
      "Epoch 11/50\n",
      "907/907 [==============================] - 1s 658us/sample - loss: 0.0872 - val_loss: 1.3550\n",
      "Epoch 12/50\n",
      "907/907 [==============================] - 1s 669us/sample - loss: 0.0493 - val_loss: 1.4484\n",
      "Epoch 13/50\n",
      "907/907 [==============================] - 1s 658us/sample - loss: 0.0323 - val_loss: 1.4118\n",
      "Epoch 14/50\n",
      "907/907 [==============================] - 1s 657us/sample - loss: 0.0226 - val_loss: 1.4421\n",
      "Epoch 15/50\n",
      "907/907 [==============================] - 1s 709us/sample - loss: 0.0181 - val_loss: 1.4843\n",
      "Epoch 16/50\n",
      "907/907 [==============================] - 1s 696us/sample - loss: 0.0130 - val_loss: 1.5139\n",
      "Epoch 17/50\n",
      "907/907 [==============================] - 1s 697us/sample - loss: 0.0102 - val_loss: 1.5354\n",
      "Epoch 18/50\n",
      "907/907 [==============================] - 1s 717us/sample - loss: 0.0083 - val_loss: 1.5798\n",
      "Epoch 19/50\n",
      "907/907 [==============================] - 1s 716us/sample - loss: 0.0072 - val_loss: 1.5970\n",
      "Epoch 20/50\n",
      "907/907 [==============================] - 1s 710us/sample - loss: 0.0064 - val_loss: 1.5866\n",
      "Epoch 21/50\n",
      "907/907 [==============================] - 1s 712us/sample - loss: 0.0057 - val_loss: 1.6080\n",
      "Epoch 22/50\n",
      "907/907 [==============================] - 1s 706us/sample - loss: 0.0052 - val_loss: 1.6365\n",
      "Epoch 23/50\n",
      "907/907 [==============================] - 1s 707us/sample - loss: 0.0047 - val_loss: 1.6488\n",
      "Epoch 24/50\n",
      "907/907 [==============================] - 1s 742us/sample - loss: 0.0043 - val_loss: 1.6744\n",
      "Epoch 25/50\n",
      "907/907 [==============================] - 1s 824us/sample - loss: 0.0039 - val_loss: 1.6793\n",
      "Epoch 26/50\n",
      "907/907 [==============================] - 1s 842us/sample - loss: 0.0036 - val_loss: 1.7072\n",
      "Epoch 27/50\n",
      "907/907 [==============================] - 1s 750us/sample - loss: 0.0034 - val_loss: 1.6993\n",
      "Epoch 28/50\n",
      "907/907 [==============================] - 1s 727us/sample - loss: 0.0032 - val_loss: 1.7140\n",
      "Epoch 29/50\n",
      "907/907 [==============================] - 1s 694us/sample - loss: 0.0030 - val_loss: 1.7239\n",
      "Epoch 30/50\n",
      "907/907 [==============================] - 1s 714us/sample - loss: 0.0028 - val_loss: 1.7266\n",
      "Epoch 31/50\n",
      "907/907 [==============================] - 1s 709us/sample - loss: 0.0026 - val_loss: 1.7446\n",
      "Epoch 32/50\n",
      "907/907 [==============================] - 1s 713us/sample - loss: 0.0025 - val_loss: 1.7502\n",
      "Epoch 33/50\n",
      "907/907 [==============================] - 1s 708us/sample - loss: 0.0023 - val_loss: 1.7513\n",
      "Epoch 34/50\n",
      "907/907 [==============================] - 1s 717us/sample - loss: 0.0022 - val_loss: 1.7587\n",
      "Epoch 35/50\n",
      "907/907 [==============================] - 1s 724us/sample - loss: 0.0021 - val_loss: 1.7613\n",
      "Epoch 36/50\n",
      "907/907 [==============================] - 1s 744us/sample - loss: 0.0020 - val_loss: 1.7671\n",
      "Epoch 37/50\n",
      "907/907 [==============================] - 1s 710us/sample - loss: 0.0019 - val_loss: 1.7706\n",
      "Epoch 38/50\n",
      "907/907 [==============================] - 1s 701us/sample - loss: 0.0018 - val_loss: 1.7755\n",
      "Epoch 39/50\n",
      "907/907 [==============================] - 1s 713us/sample - loss: 0.0017 - val_loss: 1.7832\n",
      "Epoch 40/50\n",
      "907/907 [==============================] - 1s 716us/sample - loss: 0.0016 - val_loss: 1.7797\n",
      "Epoch 41/50\n",
      "907/907 [==============================] - 1s 709us/sample - loss: 0.0016 - val_loss: 1.7855\n",
      "Epoch 42/50\n",
      "907/907 [==============================] - 1s 692us/sample - loss: 0.0015 - val_loss: 1.7848\n",
      "Epoch 43/50\n",
      "907/907 [==============================] - 1s 709us/sample - loss: 0.0014 - val_loss: 1.7846\n",
      "Epoch 44/50\n",
      "907/907 [==============================] - 1s 698us/sample - loss: 0.0014 - val_loss: 1.7894\n",
      "Epoch 45/50\n",
      "907/907 [==============================] - 1s 694us/sample - loss: 0.0013 - val_loss: 1.7983\n",
      "Epoch 46/50\n",
      "907/907 [==============================] - 1s 636us/sample - loss: 0.0013 - val_loss: 1.7920\n",
      "Epoch 47/50\n",
      "907/907 [==============================] - 1s 632us/sample - loss: 0.0012 - val_loss: 1.8017\n",
      "Epoch 48/50\n",
      "907/907 [==============================] - 1s 634us/sample - loss: 0.0012 - val_loss: 1.8008\n",
      "Epoch 49/50\n",
      "907/907 [==============================] - 1s 700us/sample - loss: 0.0011 - val_loss: 1.7981\n",
      "Epoch 50/50\n",
      "907/907 [==============================] - 1s 935us/sample - loss: 0.0011 - val_loss: 1.8116\n"
     ]
    }
   ],
   "source": [
    "# Train the MLP\n",
    "history = model.fit(X_train_3D_posed, y_train_onehot, batch_size=16, epochs=50, verbose=1, validation_split=0.1) # 90% training / 10% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 96.43%\n",
      "Test accuracy: 56.85%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_3D_posed, verbose=0)\n",
    "correct_preds = np.sum(y_train == y_train_pred, axis=0)\n",
    "train_acc = correct_preds / y_train.shape[0]\n",
    "\n",
    "print('Training accuracy: %.2f%%' % (train_acc * 100))\n",
    "\n",
    "y_test_pred = model.predict_classes(X_test_3D_posed, verbose=0)\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis=0)\n",
    "test_acc = correct_preds / y_test.shape[0]\n",
    "\n",
    "print('Test accuracy: %.2f%%' % (test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
